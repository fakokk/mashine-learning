import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd

def linear_regression(X, y):
    """
    Fit a linear regression model using the normal equation.
    Args:
        X: NumPy array of shape (n_samples, n_features)
        y: NumPy array of shape (n_samples,)
    Returns:
        theta: NumPy array of shape (n_features + 1,) containing weights and bias
    """
    ## np.c_ - конкатенация
    ## np.ones - создает столбец из единиц
    ones_column = np.ones((X.shape[0], 1), dtype=X.dtype)
    X_new = np.c_[ones_column, X]

    ## непосредственна линейная регрессия
    theta = np.linalg.inv(X_new.T@X_new)@X_new.T@y

    return theta

def predict(X, theta):
    
    ones_column = np.ones((X.shape[0], 1), dtype=X.dtype)
    X_new = np.c_[ones_column, X]

    return X_new @ theta

def normalize_features(X):

    ## Initialize the StandardScaler
    scaler = StandardScaler()
    ## Fit the scaler on the training data
    scaler.fit(X)
    ## Transform the training data
    X_normalized = scaler.transform(X)

    ## mean of each features - среднее значение каждой функции
    mean = scaler.mean_

    ## std: Standard deviation (отклонение) of each feature
    std = scaler.scale_

    return X_normalized, mean, std

def perform_eda(X, y, feature_names):
    # разведочный анализ данных

    print("\n=== Exploratory Data Analysis ===")
    
    # Summary statistics
    # Implement summary statistics: Mean, Std, Min, Max for each feature and target

    print("/nImplement summary statistics")
    # сори, тут запуталась, как сделать одинаковые отступы чтобы все выводилось в виде таблицы
    print("Feature | Mean | Std | Min | Max")

    for i, features in enumerate(feature_names):
      mean_1 = np.mean(X[:, i])
      std_1 = np.std(X[:, i])
      min_1 = np.min(X[:, i])
      max_1 = np.max(X[:, i])
      print(f"{features:10}|{mean_1:8.2f} | {std_1:10.2f} | {min_1:10.2f} | {max_1:10.2f}")

    # Correlation matrix
    # TO-DO: Implement correlation matrix and print correlation of each feature with the target

    # создает data frame
    df = pd.DataFrame(X, columns=feature_names)
    df['MedHouseVal'] = y


    # посчитаем корреляцию
    corr = df.corr()['MedHouseVal'].drop('MedHouseVal')

    print ("/nCorrelation with target: ")
    print ("Feature   |Correlation  | Strength | Direction")
    for feature in feature_names:
      corr1 = corr[feature]
      strength = "strong" if abs(corr1) > 0.5 else "medium" if abs(corr1) > 0.3 else "small"

      direction = "+" if corr1 > 0 else "-"
      print(f"{features:10}|{corr1:10.3f}|{strength}|{direction}")

## графики
## график распределения
def plot_distributions(X, y, feature_names):
    """
    Plot histograms for features and target.
    """
    print("Plotting distributions...")
    
    # 8 features + 1 target = 9 subplots
    fig, axes = plt.subplots(3, 3, figsize=(12, 10))
    
    # Plot each feature
    for i in range(8):
        row, col = i // 3, i % 3
        axes[row, col].hist(X[:, i], bins=20, alpha=0.7)
        axes[row, col].set_title(feature_names[i])
    
    # Plot target
    axes[2, 2].hist(y, bins=20, alpha=0.7, color='red')
    axes[2, 2].set_title('Target (MedHouseVal)')
    
    plt.tight_layout()
    plt.show()

## график корреляции
def plot_correlation_heatmap(X, y, feature_names):
    """
    Plot correlation heatmap.
    """
    print("Plotting correlations...")
    
    # Make dataframe with features and target
    df = pd.DataFrame(X, columns=feature_names)
    df['Target'] = y
    
    # Simple heatmap
    plt.figure(figsize=(8, 6))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
    plt.title('Feature Correlations')
    plt.show()

## предсказание
def plot_predictions(y_test, y_pred):
    """
    Plot predictions vs actual values.
    """
    print("Plotting predictions...")
    
    plt.figure(figsize=(6, 6))
    plt.scatter(y_test, y_pred, alpha=0.5)
    
    # Perfect prediction line
    min_val = min(y_test.min(), y_pred.min())
    max_val = max(y_test.max(), y_pred.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--')
    
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.title('Predictions vs Actual')
    plt.grid(True)
    plt.show()

# Load California Housing dataset
data = fetch_california_housing()
X, y = data.data, data.target  # X: features, y: median house value
feature_names = data.feature_names

# Perform EDA
perform_eda(X, y, feature_names)
    
# Visualize distributions
print(f"Plotting feature and target distributions...")
plot_distributions(X, y, feature_names)
    
# Visualize correlation heatmap
print(f"Plotting correlation heatmap...")
plot_correlation_heatmap(X, y, feature_names)
    
# Normalize features
X_normalized, mean, std = normalize_features(X)
    
# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)
    
# Fit model
theta = linear_regression(X_train, y_train)
print(f"Model Weights: {theta[1:]}")
print(f"Model Bias: {theta[0]}")
    
# Predict on test set
y_pred = predict(X_test, theta)
    
# Compute Mean Squared Error
mse = np.mean((y_test - y_pred)**2)
print(f"Mean Squared Error on test set: {mse}")
    
# Example predictions for first 5 test samples
print(f"First 5 test predictions: {y_pred[:5]}")
print(f"First 5 actual values: {y_test[:5]}")
    
# Visualize predictions
print("Plotting predicted vs actual values...")
plot_predictions(y_test, y_pred)

# насчёт графиков не уверена, раньше не строила графики((!!!